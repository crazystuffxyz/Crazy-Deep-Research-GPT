import{Ollama}from"ollama";import{getFetchResults,getSearchResults}from"./interactWithInternet.js";import pLimit from"p-limit";const ollama=new Ollama,MAX_SERP_GENERATION_RETRIES=2,MAX_LINKS_PER_QUERY=3,FETCH_CONCURRENCY=3,CITATION_SUMMARY_SEPARATOR="\n---SUMMARY---\n",DEFAULT_LITE_RESEARCH_HELPER_MODEL="qwen2.5vl:3b",DEFAULT_LITE_RESEARCH_PAPER_MODEL="qwen2.5vl:3b";function isValidLink(e,t){if(t||(t=new Set),!e||"string"!=typeof e||t.has(e)||e.endsWith(".pdf"))return!1;try{const t=new URL(e),a=t.hostname.toLowerCase();return![".pdf",".doc",".docx",".ppt",".pptx",".xls",".xlsx",".zip",".rar",".exe",".dmg",".pkg",".mp3",".mp4",".mov",".avi",".iso"].some((e=>t.pathname.toLowerCase().endsWith(e)))&&(a.endsWith(".org")||a.endsWith(".gov")||a.endsWith(".edu")||a.endsWith(".com")||a.endsWith(".net")||a.includes("wikipedia.org")||a.includes("github.io")||!a.match(/\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}/))}catch(e){return!1}}function parseSerpQueries(e){if(!e||"string"!=typeof e)return[];const t=e.split("\n"),a=[],n=/^\s*searchUp\("((?:[^"\\]|\\.)*)"\)\s*$/i;for(const e of t){const t=e.trim().match(n);t&&void 0!==t[1]&&"query"!==t[1].toLowerCase()&&t[1].length>3&&a.push(t[1])}return a}async function generateSerpQueries(e,t,a,n,r,i){let s=0;const o=t.slice(-3).map((e=>`${e.role}: ${e.content.substring(0,150)}...`)).join("\n");for(;s<=r;){s++,n({status:"Generating SERP Queries",detail:`Attempt ${s}/${r+1} for goal: "${e.substring(0,50)}..."`,isFinal:!1});try{const t={model:i,messages:[{role:"system",content:`You are an AI assistant tasked with generating search queries.\n\nYour user's location (e.g., city, region) might be implicitly or explicitly available in the conversation history or research goal. You MUST IGNORE this location information UNLESS the research goal or user query *specifically and explicitly requires* location-based information (e.g., for queries like "weather in [city]", "restaurants near me", "current events in [specific location]"). For general research topics, location is irrelevant and should not influence the queries.\n\nBased on the research goal and recent conversation history, generate exactly ${a} unique and diverse SERP (Search Engine Results Page) queries.\n\nEach query MUST be formatted *exactly* as follows, with each on a new line:\nsearchUp("your search query text here")\n\nFor example:\nsearchUp("symptoms of seasonal flu")\nsearchUp("latest advancements in quantum computing")\nsearchUp("economic impact of renewable energy sources")\n\nFollow this format precisely. Do NOT add any other text, explanations, or numbering before, between, or after the list of searchUp(...) calls. Only output the searchUp(...) lines. Deviations from this format will cause the process to fail.\nEnsure the queries generated are distinct and aim to cover different aspects of the research goal if appropriate.\n\nConversation History (for context):\n${o}`},{role:"user",content:`Research Goal: ${e}`}],stream:!1,options:{temperature:.5}},l=await ollama.chat(t),u=l.message?.content||"";console.log("--- Raw SERP Output from AI ---"),console.log(u),console.log("-------------------------------");const c=parseSerpQueries(u);if(c.length>=a){const e=[...new Set(c)];return n({status:"Generated SERP Queries",detail:`Found ${e.length} unique queries: ${e.slice(0,a).map((e=>`"${e}"`)).join(", ")}`,isFinal:!1}),e.slice(0,a)}if(n({status:"Warning",detail:`AI did not generate enough valid SERP queries (Attempt ${s}, got ${c.length}, need ${a}). Raw: ${u.substring(0,100)}...`,isFinal:!1}),s>r&&c.length>0)return n({status:"Generated SERP Queries (Partial)",detail:`Using ${c.length} queries after retries.`,isFinal:!1}),c.slice(0,a);if(s>r)throw new Error("No valid SERP queries generated after retries.")}catch(e){if(n({status:"Error Generating SERP",error:e.message,detail:`Attempt ${s}`,isFinal:!1}),s>r)throw new Error(`Failed to generate SERP queries after ${s} attempts: ${e.message}`)}}throw new Error("Failed to generate SERP queries within retry limits.")}async function generateCitationAndSummary(e,t,a,n,r,i,s,o){r({status:"Generating Citation & Summary",detail:`${i} For URL: ${e} (HeavyDuty: ${o})`,isFinal:!1});try{const n=1e4,l=t.length>n?t.substring(0,n)+"...":t;if(l.startsWith("Error:")||l.length<150)return r({status:"Skipping Citation/Summary",detail:`${i} Content too short or error: ${e}`,isFinal:!1}),null;const u=[{role:"system",content:"Based on the provided URL, generate a full MLA 9th edition citation.\nEnsure all available details (author, publication date, site name, publisher, access date) are included if discernible from the URL or common knowledge for the site.\nIf some details are missing, create the best possible citation.\nOutput *only* the MLA citation text. Do not add any other explanations or surrounding text."},{role:"user",content:`URL: ${e}`}];let c=`Analyze the provided text content in relation to the overall research goal: "${a.substring(0,150)}...".\nFocus on extracting key facts, arguments, and data directly relevant to this goal.\nOutput *only* the summary text. Do not add any other explanations or surrounding text.`;c+=o?"\n\nThis is a HEAVY DUTY research task. The summary must be extremely comprehensive, detailed, and analytical.\nAim for at least 10-15 well-developed paragraphs, thoroughly exploring the nuances of the provided content in relation to the research goal.\nSynthesize information thoughtfully. Do not just list facts; explain their significance and interconnections.\nThe summary should be suitable for inclusion in a PhD-level research paper.":"\nProvide a detailed summary of 5-7 sentences.";const h=[{role:"system",content:c},{role:"user",content:`URL: ${e}\n\nContent:\n${l}`}],m=ollama.chat({model:s,messages:u,stream:!1,options:{temperature:.2}}),d=ollama.chat({model:s,messages:h,stream:!1,options:{temperature:o?.4:.5}}),[g,p]=await Promise.all([m,d]),y=g.message?.content?.trim()||"",f=p.message?.content?.trim()||"";if(y&&f&&f.length>(o?100:20))return{citation:y,summary:f};{let t=[];return y||t.push("Citation was empty."),f?f.length<=(o?100:20)&&t.push(`Summary was too short (got ${f.length} chars).`):t.push("Summary was empty."),r({status:"Warning Generating Citation/Summary Parts",detail:`${i} URL: ${e}. ${t.join(" ")} Citation: "${y.substring(0,50)}...", Summary: "${f.substring(0,50)}..."`,isFinal:!1}),{citation:y||"Automated citation generation failed.",summary:f||(o?"Automated comprehensive summary generation failed.":"Automated summary generation failed.")}}}catch(t){return r({status:"Error Generating Citation/Summary",detail:`${i} URL: ${e}`,error:t.message,isFinal:!1}),{citation:"Error generating citation.",summary:"Error generating summary."}}}async function processSingleSerpQuery(e,t,a,n,r,i,s,o,l,u){i({status:"Processing SERP Query",detail:`${s} Query: "${e}"`,isFinal:!1});let c=[];try{if(c=await getSearchResults(e),!c||0===c.length)return i({status:"No Search Results",detail:`${s} No results for "${e}"`,isFinal:!1}),[];i({status:"Got Search Results",detail:`${s} Found ${c.length} results for "${e}"`,isFinal:!1})}catch(t){return i({status:"Error Searching",detail:`${s} Query: "${e}"`,error:t.message,isFinal:!1}),[]}const h=[];for(const e of c)if(isValidLink(e.link,n)&&(h.push(e.link),h.length>=MAX_LINKS_PER_QUERY))break;if(h.forEach((e=>n.add(e))),l&&h.length>0&&h.forEach((e=>{i({heavyDutyResearchUpdate:{visitedUrl:e,statusDetail:`Marked ${e} as visited.`},isFinal:!1,heavyDutyResearchId:l})})),0===h.length)return i({status:"No New Valid Links",detail:`${s} No new usable links found for "${e}".`,isFinal:!1}),[];i({status:"Fetching & Processing Content",detail:`${s} Processing ${h.length} link(s) for "${e}"`,isFinal:!1});const m=h.map(((e,n)=>r((async()=>{const r=`${s} Link ${n+1}/${h.length}`;try{i({status:"Fetching Content",detail:`${r} Fetching: ${e}`,isFinal:!1});const n=await getFetchResults(e);if("string"!=typeof n||n.startsWith("Error:"))return i({status:"Error Fetching Content",detail:`${r} Failed: ${e}`,error:n||"Unknown fetch error",isFinal:!1}),null;i({status:"Fetched Content",detail:`${r} Success: ${e}`,isFinal:!1});const s=await generateCitationAndSummary(e,n,t,a,i,r,o,u);if(s&&s.citation&&s.summary&&s.summary.length>20){const t={url:e,citation:s.citation,summary:s.summary};return l&&i({heavyDutyResearchUpdate:{processedDataChunk:t,statusDetail:`Processed ${e}`},isFinal:!1,heavyDutyResearchId:l}),t}if(s){i({status:"Warning",detail:`${r} Partial data from citation/summary for ${e}. Citation: ${s.citation?.substring(0,30)}... Summary: ${s.summary?.substring(0,30)}...`,isFinal:!1});const t={url:e,citation:s.citation||"Automated citation failed.",summary:s.summary||"Automated summary failed."};return l&&i({heavyDutyResearchUpdate:{processedDataChunk:t,statusDetail:`Processed (partially) ${e}`},isFinal:!1,heavyDutyResearchId:l}),t}return null}catch(t){return i({status:"Error Processing Link",detail:`${r} URL: ${e}`,error:t.message,isFinal:!1}),null}}))));return(await Promise.all(m)).filter((e=>null!==e))}async function generateFinalReport(e,t,a,n,r,i,s,o){const l=o?Math.max(15,Math.min(25,2*e.length)):Math.max(5,Math.min(10,1.5*e.length));let u="",c="";if(e.length>0){i({status:"Generating Final Report",detail:`Synthesizing paper from ${e.length} summaries. Target: ~${l} paragraphs. Heavy Duty: ${o}`,isFinal:!1});try{const n=e.map(((e,t)=>`Source ${t+1} (URL: ${e.url}):\nSummary: ${e.summary}\nCitation: ${e.citation}`)).join("\n\n---\n\n"),r=a.slice(-3).map((e=>`${e.role}: ${e.content.substring(0,150)}...`)).join("\n"),c={model:s,messages:[{role:"system",content:`You are a meticulous research assistant. Based *only* on the provided research summaries and their citations, and considering the original query and recent conversation, write a comprehensive research paper.\nOriginal Query: "${t}"\nRecent Conversation Context:\n${r}\n\n${o?`This is a HEAVY DUTY research task. The paper must be extremely detailed, meticulous, and PhD-level in quality. It should be at least ${l} well-developed paragraphs long, offering deep analysis and synthesis.`:`This is a LITE research task. The paper should be well-structured and informative, around ${l} paragraphs.`}\n\n- Synthesize findings from the summaries into a coherent narrative.\n- Structure: Clear Introduction (stating scope and main findings), Body (themed paragraphs with supporting details from sources, critical analysis if possible for heavy duty), Conclusion (summarizing key takeaways and potential implications).\n- Do *not* refer to "Source 1", "Source 2", etc. Integrate information smoothly, as if you are the author who has read these sources.\n- For Heavy Duty: Ensure extensive citations are implicitly woven by using information clearly tied to the provided summaries. The language should be academic and precise.\n- The final output should be ONLY the research paper text. A separate list of works cited will be compiled later from the provided citations.\n- Adhere strictly to the information within the provided summaries. Do not introduce external knowledge.\n- Ensure a logical flow and strong argumentation, especially for Heavy Duty mode.\n`},{role:"user",content:`Research Materials (Summaries & Citations):\n\n${n}`}],stream:!0,options:{temperature:o?.4:.6}};let h="";const m=await ollama.chat(c);for await(const e of m)h+=e.message.content,(h.length%500<(e.message.content?.length||0)||e.done)&&i({status:"Generating Final Report",detail:"Writing paper...",progress:h.length,partialPaper:h.substring(0,2e3)+"...",isFinal:!1});u=h.trim(),i({status:"Generated Research Paper",detail:"Paper generation complete.",isFinal:!1})}catch(e){i({status:"Error Generating Paper",error:e.message,isFinal:!1}),u=`Error generating research paper: ${e.message}`}}else u="No valid summaries were generated to create a research paper.",i({status:"Skipped Paper Generation",detail:"No summaries available.",isFinal:!1});return c=e.length>0?e.map((e=>e.citation)).filter((e=>e&&""!==e.trim())).map((e=>`- ${e}`)).join("\n"):"No citations were generated.",{researchPaper:u,citations:c}}export async function deepResearch(e,t,a=3,n=2,r=[],i=new Set,s=(e=>console.log(JSON.stringify(e))),o=1,l=!1,u,c,h,m=null){const d=u||(l?void 0:"qwen2.5vl:3b"),g=c||(l?void 0:"qwen2.5vl:3b"),p=h||(l?void 0:"qwen2.5vl:3b");s({status:"Starting Research Level",detail:`Query: "${e.substring(0,70)}...", Depth: ${o}/${n}, Breadth: ${a}, HeavyDuty: ${l}`,isFinal:!1});let y,f=e;if(o>1&&r.length>0){const t=r.slice(-Math.min(3,r.length)).map((e=>e.summary)).join("\n");f=`Original goal: "${e}". Prior findings from ${Math.min(3,r.length)} sources: "${t.substring(0,200)}...". Now, explore related sub-topics, alternative viewpoints, or delve deeper into specific aspects mentioned. Generate queries for this next level of investigation.`}try{y=await generateSerpQueries(f,t,a,s,2,d)}catch(i){if(s({status:"Failed",error:`Halting research: SERP generation failure: ${i.message}`,isFinal:1===o}),1===o){const i=await generateFinalReport(r,e,t,a,n,s,p,l);return void s({status:"Complete",finalResult:i,isFinal:!0})}y=[]}y&&0!==y.length||s({status:"No SERP Queries Generated for this Level",detail:"Proceeding with existing data or concluding.",isFinal:!1});const $=pLimit(3),v=[];if(y&&y.length>0){const a=y.map(((a,n)=>{const r=`(Lvl:${o}, Q:${n+1}/${y.length})`;return processSingleSerpQuery(a,e,t,i,$,s,r,g,m,l)}));(await Promise.all(a)).forEach((e=>{e&&e.length>0&&v.push(...e)}))}const R=[...r,...v];if(o<n)return s({status:"Starting Deeper Research Level",detail:`Moving to Depth ${o+1}`,isFinal:!1}),deepResearch(e,t,Math.max(1,Math.ceil(a/(l?1.2:1.5))),n,R,i,s,o+1,l,u,c,h,m);{s({status:"Max Depth Reached",detail:`Total processed items for report: ${R.length}`,isFinal:!1});const r=new Map;R.forEach((e=>{e&&e.url&&r.set(e.url,e)}));const i=Array.from(r.values()),o=await generateFinalReport(i,e,t,a,n,s,p,l);return void s({status:"Complete",finalResult:o,isFinal:!0,heavyDutyResearchId:l?m:void 0})}}